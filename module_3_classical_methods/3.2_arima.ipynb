{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bce813-4c66-4678-a7d7-d865f7d3c859",
   "metadata": {},
   "source": [
    "# Classical Forecasting Methods: ARIMA\n",
    "\n",
    "**Approximate Learning Time**: Up to 3 hours \n",
    "\n",
    "--- \n",
    "\n",
    "In this module, we will explore the following classical time series forecasting methods:\n",
    "\n",
    "- **Auto-Regressive Integrated Moving Average (ARIMA) Models:** Covered in Notebook 3.1.\n",
    "- **Holt-Winters Model:** An approach to exponential smoothing for time series forecasting, covered in Notebook 3.2.\n",
    "- **Vector Auto-Regression (VAR):** A method for modeling multiple time series simultaneously, covered in Notebook 3.3.\n",
    "\n",
    "We will follow a standard workflow that includes:\n",
    "- Splitting the data into training, validation, and test subsets.\n",
    "- Fitting the models on a predefined set of hyperparameters.\n",
    "- Conducting a hyperparameter search to find the best-performing model.\n",
    "- Evaluating test metrics using the best model.\n",
    "\n",
    "---\n",
    "\n",
    "## SARIMA Model\n",
    "\n",
    "\n",
    "**Autoregressive (AR) models** assume that future values are a linear function of past values. The order of the AR model, denoted by $p$, is the number of past values used to predict future values. The residual error, $e_t$, is assumed to be white noise.\n",
    "\n",
    "**Moving Average (MA) models** assume that the future values can be modeled using past error terms ($e_t$). The term \"moving average\" here refers to a weighted sum of past errors, not to a traditional moving average over the data. Importantly, MA models cannot be applied without first modeling the errors through an AR process, so MA models are not standalone for time series prediction. The order of MA model, denoted by $q$, is the number of past error terms to be used. \n",
    "\n",
    "**ARMA (Autoregressive Moving Average) models** combine the AR and MA approaches, modeling future values as a linear combination of both past values and past error terms. The order of an ARMA model is given by $(p, q)$, where $p$ is the AR order and $q$ is the MA order.\n",
    "\n",
    "The core assumption of AR and ARMA models is that the underlying time series is stationary. If a series is non-stationary, it can be transformed to achieve stationarity, commonly by **differencing**â€”subtracting consecutive values. When differencing is incorporated into an ARMA model, the result is an **ARIMA (Autoregressive Integrated Moving Average)** model, where:\n",
    "- $p$ is the AR order,\n",
    "- $d$ is the number of differencing steps,\n",
    "- $q$ is the MA order.\n",
    "\n",
    "The order of an ARIMA model is specified as $(p, d, q)$.\n",
    "\n",
    "\n",
    "**SARIMA (Seasonal ARIMA)** explicitly accounts for seasonality in time series data. Seasonality refers to patterns that repeat after a fixed time period, or \"season.\" Incorporating seasonality into the model can enhance performance by reducing the search space for parameters.\n",
    "\n",
    "SARIMA adds seasonal terms to the ARIMA model, introducing seasonal parameters $(P, D, Q, S)$ where:\n",
    "- $P$ is the seasonal autoregressive order,\n",
    "- $D$ is the seasonal differencing order,\n",
    "- $Q$ is the seasonal moving average order,\n",
    "- $S$ is the length of the seasonal cycle (e.g., number of time steps in a season).\n",
    "\n",
    "For example, $(0,1,0,4)$ would model a series with seasonality that repeats every 4 time steps, and the differencing would take into account changes between values 4 time steps apart.\n",
    "\n",
    "\n",
    "**Note**: The **ARIMA model** is designed for univariate time series, meaning it models one time series at a time. Therefore, we will build individual univariate models for each of the time series in our dataset. To handle **multivariate time series**, where multiple variables are modeled together, we will introduce the **Vector Autoregression (VAR)** approach later in this module.\n",
    "\n",
    "---\n",
    "\n",
    "Let's load the log daily returns of exchange rates, and split the data into train, validation, and test subsets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a476e-7956-4ae3-b5bd-17d82f8b91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# To avoid flooding of the screen with convergence warnings during hyperparameter tuning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## WARNING: To compare different models on the same horizon, keep this same across the notebooks\n",
    "from termcolor import colored\n",
    "import sys; sys.path.append(\"../\")\n",
    "import utils\n",
    "\n",
    "FORECASTING_HORIZON = [4, 8, 12] # weeks \n",
    "MAX_FORECASTING_HORIZON = max(FORECASTING_HORIZON)\n",
    "\n",
    "SEQUENCE_LENGTH = 2 * MAX_FORECASTING_HORIZON\n",
    "PREDICTION_LENGTH = MAX_FORECASTING_HORIZON\n",
    "\n",
    "DIRECTORY_PATH_TO_SAVE_RESULTS = pathlib.Path('../results/DIY/').resolve()\n",
    "MODEL_NAME = \"ARIMA\"\n",
    "\n",
    "RESULTS_DIRECTORY = DIRECTORY_PATH_TO_SAVE_RESULTS / MODEL_NAME\n",
    "if RESULTS_DIRECTORY.exists():\n",
    "    print(colored(f'Directory {str(RESULTS_DIRECTORY)} already exists.'\n",
    "           '\\nThis notebook will overwrite results in the same directory.'\n",
    "           '\\nYou can also create a new directory if you want to keep this directory untouched.'\n",
    "           ' Just change the `MODEL_NAME` in this notebook.\\n', \"red\" ))\n",
    "else:\n",
    "    RESULTS_DIRECTORY.mkdir(parents=True)\n",
    "\n",
    "# load data\n",
    "data, transformed_data = utils.load_tutotrial_data(dataset='exchange_rate', log_transform=True)\n",
    "data = transformed_data\n",
    "\n",
    "## DATA SPLITTING\n",
    "train_val_data = data.iloc[:-MAX_FORECASTING_HORIZON]\n",
    "train_data, val_data = train_val_data.iloc[:-MAX_FORECASTING_HORIZON], train_val_data.iloc[-MAX_FORECASTING_HORIZON:]\n",
    "test_data = data.iloc[-MAX_FORECASTING_HORIZON:]\n",
    "\n",
    "print(f\"Number of steps in training data: {len(train_data)}\\nNumber of steps in validation data: {len(val_data)}\\nNumber of steps in test data: {len(test_data)}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa5355-98e5-486e-9ba4-8670dfdbcaa5",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Hyperparameter Tuning\n",
    "\n",
    "The hyperparameters for the **SARIMA model** include parameters for both the non-seasonal order $(p, d, q)$ and the seasonal order $(P, D, Q, S)$. Given these hyperparameters, we fit the model to the data. SARIMA models minimize an objective function, typically the likelihood, which is summarized by the **Akaike Information Criterion (AIC)**. \n",
    "\n",
    "However, the fitness criterion used during model fitting (AIC) does not necessarily correspond to real-world performance metrics such as the **Mean Absolute Scaled Error (MASE)**, which is more aligned with practical forecasting needs. Therefore, we evaluate the model's performance on the validation dataset to select the best hyperparameters.\n",
    "\n",
    "For this tutorial, we will explore the following range of hyperparameters for the SARIMA model:\n",
    "\n",
    "- $p \\in \\{1, 2, 3\\}$\n",
    "- $d \\in \\{0, 1\\}$\n",
    "- $q \\in \\{1, 2, 3\\}$\n",
    "- $s \\in \\{0, 4, 12\\}$\n",
    "\n",
    "One of the simplest ways to find the best combination of these hyperparameters is through a brute-force search (grid search), which evaluates all possible combinations. However, this approach becomes computationally expensive as the search space grows. To overcome this, more sophisticated methods such as **Bayesian optimization** can be employed. Libraries like [`pmdarima.auto_arima`](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.AutoARIMA.html#pmdarima.arima.AutoARIMA) implement intelligent hyperparameter search strategies, including Bayesian methods.\n",
    "\n",
    "In this tutorial, we will stick to brute-force search, but leave it as an exercise for you to explore AutoARIMA for smarter hyperparameter tuning.\n",
    "\n",
    "**Note:** Some parameters might lead to warnings as the underlying model might be under-constrained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e705c-4d0a-4c14-b13b-006eed09ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid\n",
    "p_values = range(1, 4)\n",
    "q_values = range(1, 3)\n",
    "d_values = range(0, 2)\n",
    "s_values = [0, 4, 12] # a large value will result in long running times\n",
    "pdqs = list(itertools.product(p_values, d_values, q_values, s_values))\n",
    "print(f\"Number of parameters: {len(pdqs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf22b8-1dc3-43e9-9f91-214c6f38be81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid search\n",
    "\n",
    "# only for understanding\n",
    "best_aic = {}\n",
    "best_aic_model = {}\n",
    "\n",
    "# we will use the models with best mase on validation dataset\n",
    "best_mase = {}\n",
    "best_mase_model = {}\n",
    "for col in tqdm(train_data.columns, leave=False):\n",
    "    ts = train_data[col]\n",
    "    best_aic[col] = np.inf\n",
    "    best_mase[col] = np.inf\n",
    "    \n",
    "    for p,d,q,s  in tqdm(pdqs, leave=False, desc=f\"Column:{col}\"):\n",
    "        if s == 0:\n",
    "            seasonal_order = None\n",
    "        else:\n",
    "            seasonal_order=(0, 1, 0, s)\n",
    "\n",
    "        model = SARIMAX(\n",
    "            ts,\n",
    "            trend=\"c\",\n",
    "            order=(p, d, q), # non-seasonal ARIMA parameters\n",
    "            seasonal_order=seasonal_order,\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False,\n",
    "        )\n",
    "    \n",
    "        results = model.fit(disp=False)\n",
    "        predictions = results.get_forecast(steps=len(val_data)) # how to get forecasts?\n",
    "\n",
    "        # SARIMAX returns mean and standard errors\n",
    "        forecast = predictions.predicted_mean.values \n",
    "        actual = val_data[col].values\n",
    "        mase = utils.mean_absolute_scaled_error(forecast, actual, insample_data=ts.values)\n",
    "\n",
    "        if mase < best_mase[col]:\n",
    "            best_mase[col] = mase\n",
    "            best_mase_model[col] = (model, results, (p, d, q, s))\n",
    "        \n",
    "        if results.aic < best_aic[col]:\n",
    "            best_aic[col] = results.aic\n",
    "            best_aic_model[col] = (model, results, (p, d, q, s))\n",
    "    \n",
    "    print(f\"Col: {col}. Best AIC parameters: {best_aic_model[col][-1]}. Best AIC:{best_aic[col]}. Best Mase: {best_mase[col]}. Best Mase Parameters: {best_mase_model[col][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c90ce6-2a35-44ea-bafa-2853c6703be4",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- As suspected, best hyperparameters corresponding to MASE aren't the same as that which performs the best according to AIC\n",
    "\n",
    "---\n",
    "\n",
    "## Refit on Train-Val Subset & Forecast\n",
    "\n",
    "To measure the model's performance on the test data, we will first retrain the model using the combined train-validation dataset. Then, we will compute the MASE metric on the test dataset to evaluate its performance.\n",
    "Additionally, we will store the test predictions for later comparison with other forecasting methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958373ad-ddea-4eca-bf21-30c61ce7b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "best_model_metrics = {}\n",
    "for col in test_data.columns:\n",
    "    best_model_metrics[col] = {}\n",
    "    ts = train_val_data[col]\n",
    "    \n",
    "    # retrain the model with best mase parameters on train_val_data\n",
    "    p, d, q, s = best_mase_model[col][2]\n",
    "    ts = train_val_data[col]\n",
    "    if s == 0:\n",
    "        seasonal_order = None\n",
    "    else:\n",
    "        seasonal_order=(0, 1, 0, s)\n",
    "    \n",
    "    model = SARIMAX(\n",
    "        ts,\n",
    "        trend=\"c\",\n",
    "        order=(p, d, q),\n",
    "        seasonal_order=seasonal_order,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "    # get metrics and predictions\n",
    "    predictions = results.get_forecast(steps=len(test_data))\n",
    "    test_predictions[f\"{MODEL_NAME}_{col}_mean\"] = predictions.predicted_mean.values\n",
    "    test_predictions[f\"{MODEL_NAME}_{col}_se\"] = predictions.se_mean.values\n",
    "\n",
    "# store these predictions \n",
    "test_predictions_df = pd.DataFrame(test_predictions, index=test_data.index)\n",
    "\n",
    "test_predictions_df.to_csv(f\"{str(RESULTS_DIRECTORY)}/predictions.csv\", index=True)\n",
    "print(test_predictions_df.shape)\n",
    "test_predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597da55f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluate\n",
    "\n",
    "Let's compute the metrics by comparing the predictions with that of the target data. Note that we will have to rename the columns of the dataframe to match the expected column names by the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dbbab-5ce9-4c33-bac1-fe67ac24bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MASE metrics\n",
    "model_metrics, records = utils.get_mase_metrics(\n",
    "    historical_data=train_val_data,\n",
    "    test_predictions=test_predictions_df[[x for x in test_predictions_df.columns if 'mean' in x]].rename(\n",
    "            columns={x:x.split(\"_\")[1] for x in test_predictions_df.columns\n",
    "        }),\n",
    "    target_data=test_data,\n",
    "    forecasting_horizons=FORECASTING_HORIZON,\n",
    "    columns=data.columns, \n",
    "    model_name=MODEL_NAME,\n",
    ")\n",
    "\n",
    "records = pd.DataFrame(records)\n",
    "\n",
    "records.to_csv(f\"{str(RESULTS_DIRECTORY)}/metrics.csv\", index=False)\n",
    "records[['col', 'horizon', 'mase']].pivot(index=['horizon'], columns='col')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971c6e5",
   "metadata": {},
   "source": [
    "**Exercise**: What does these values mean?\n",
    "\n",
    "---\n",
    "\n",
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_results(path=DIRECTORY_PATH_TO_SAVE_RESULTS, metric='mase')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a22b73-a9e8-4717-aeeb-734e105d6338",
   "metadata": {},
   "source": [
    "**Exercise**: Change `metric` in the above function to \"mae\" or \"mse\" and observe the values. What do you think about the performance of the models?\n",
    "\n",
    "---\n",
    "\n",
    "## Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0184f-9489-4b48-989f-32c1014324a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = utils.plot_forecasts(\n",
    "    historical_data=train_val_data,\n",
    "    forecast_directory_path=DIRECTORY_PATH_TO_SAVE_RESULTS,\n",
    "    target_data=test_data,\n",
    "    columns=data.columns,\n",
    "    n_history_to_plot=10, \n",
    "    forecasting_horizon=MAX_FORECASTING_HORIZON,\n",
    "    dpi=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201baa6-fcc3-49b1-8afa-2ebf2d61a742",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Conclusions\n",
    "\n",
    "We learned about ARIMA models, searched for the best ARIMA model for 8 time series in the dataset, and finally, evalauted its performance using the MASE metric. \n",
    "\n",
    "--- \n",
    "\n",
    "## Exercises\n",
    "\n",
    "- The [`pmdarima` library](https://alkaline-ml.com/pmdarima/index.html) in Python provides an automatic parameter tuning feature for ARIMA models. Refer to the [documentation](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.AutoARIMA.html#pmdarima.arima.AutoARIMA) for `pmd.auto_arima` to familiarize yourself with the parameters. Note that it does not perform hyperparameter search on the seasonality parameter, so you will need to manually select the best seasonality parameter based on the AIC score or validation score.\n",
    "\n",
    "- Apply a normalization procedure (e.g., **min-max scaling**) to the data, ensuring that only the training data is used for fitting the scaler. Perform the modeling process on the normalized data and, after generating the final model's predictions, invert the normalization to return the output to its original scale. See `sklearn.preprocessing.MinMaxScaler` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html))\n",
    "\n",
    "- Additionally, perform the modeling on the **raw data**, without applying any transformation (such as converting it into log daily returns), to compare results directly with the untransformed dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- To learn about other classical methods, proceed to the notebook 3.3 (exponential smoothing method) or notebook 3.4 (Vector-Autoregression method)\n",
    "\n",
    "- To learn about other machine learning based approaches, check out the module 4 (XGBoost), module 5 (LSTM-based models), module 6 (Transformer based models), or module 7 (LLM-based models).\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
